{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You want to reduce the features to be used by a classifier\n",
    "\n",
    "Try linear discriminant analysis (LDA) to project the features onto component\n",
    "axes that maximize the separation of classes:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 4\n",
      "Reduced number of features: 1\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# Load Iris flower dataset:\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "# Create and run an LDA, then use it to transform the features\n",
    "lda = LinearDiscriminantAnalysis(n_components=1)\n",
    "features_lda = lda.fit(features, target).transform(features)\n",
    "# Print the number of features\n",
    "print(\"Original number of features:\", features.shape[1])\n",
    "print(\"Reduced number of features:\", features_lda.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use explained_variance_ratio_ to view the amount of variance\n",
    "explained by each component. In our solution the single component explained\n",
    "over 99% of the variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9912126])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA is a classification that is also a popular technique for dimensionality\n",
    "reduction. LDA works similarly to principal component analysis (PCA) in that it\n",
    "projects our feature space onto a lower-dimensional space. However, in PCA we\n",
    "were only interested in the component axes that maximize the variance in the\n",
    "data, while in LDA we have the additional goal of maximizing the differences\n",
    "between classes. In this pictured example, we have data comprising two target\n",
    "classes and two features. If we project the data onto the y-axis, the two classes\n",
    "are not easily separable (i.e., they overlap), while if we project the data onto the\n",
    "x-axis, we are left with a feature vector (i.e., we reduced our dimensionality by\n",
    "one) that still preserves class separability. In the real world, of course, the\n",
    "relationship between the classes will be more complex and the dimensionality will be higher, but the concept remains the same\n",
    "\n",
    "![](./pics/maxmizing%20class%20seperability.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In scikit-learn, LDA is implemented using LinearDiscriminantAnalysis,\n",
    "which includes a parameter, n_components, indicating the number of features\n",
    "we want returned. To figure out what argument value to use with n_components\n",
    "(e.g., how many parameters to keep), we can take advantage of the fact that\n",
    "explained_variance_ratio_ tells us the variance explained by each outputted\n",
    "feature and is a sorted array. For example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9912126])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifically, we can run LinearDiscriminantAnalysis with n_components set\n",
    "to None to return the ratio of variance explained by every component feature,\n",
    "then calculate how many components are required to get above some threshold\n",
    "of variance explained (often 0.95 or 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and run LDA\n",
    "lda = LinearDiscriminantAnalysis(n_components=None)\n",
    "features_lda = lda.fit(features, target)\n",
    "# Create array of explained variance ratios\n",
    "lda_var_ratios = lda.explained_variance_ratio_\n",
    "# Create function\n",
    "def select_n_components(var_ratio, goal_var: float) -> int:\n",
    "    # Set initial variance explained so far\n",
    "    total_variance = 0.0\n",
    "    # Set initial number of features\n",
    "    n_components = 0\n",
    "# For the explained variance of each feature:\n",
    "    for explained_variance in var_ratio:\n",
    "# Add the explained variance to the total\n",
    "        total_variance += explained_variance\n",
    "# Add one to the number of components\n",
    "        n_components += 1\n",
    "# If we reach our goal level of explained variance\n",
    "        if total_variance >= goal_var:\n",
    "# End the loop\n",
    "            break\n",
    "# Return the number of components\n",
    "    return n_components\n",
    "# Run function\n",
    "select_n_components(lda_var_ratios, 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b4f27d9b98637a93dfc92790c67a6714c8bfd98755bed637fb445c0198654de1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
