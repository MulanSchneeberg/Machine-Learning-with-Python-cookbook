{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have a sparse feature matrix and want to reduce the dimensionality.\n",
    "\n",
    "Use Truncated Singular Value Decomposition (TSVD):\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "# Load the data\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 64\n",
      "Reduced number of features: 10\n"
     ]
    }
   ],
   "source": [
    "# Standardize feature matrix\n",
    "features = StandardScaler().fit_transform(digits.data)\n",
    "# Make sparse matrix\n",
    "features_sparse = csr_matrix(features)\n",
    "# Create a TSVD\n",
    "tsvd = TruncatedSVD(n_components=10)\n",
    "# Conduct TSVD on sparse matrix\n",
    "features_sparse_tsvd = tsvd.fit(features_sparse).transform(features_sparse)\n",
    "# Show results\n",
    "print(\"Original number of features:\", features_sparse.shape[1])\n",
    "print(\"Reduced number of features:\", features_sparse_tsvd.shape[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TSVD is similar to PCA and in fact, PCA actually often uses non-truncated\n",
    "Singular Value Decomposition (SVD) in one of its steps. In regular SVD, given\n",
    "d features, SVD will create factor matrices that are d × d, whereas TSVD will\n",
    "return factors that are n × n, where n is previously specified by a parameter. The\n",
    "practical advantage of TSVD is that unlike PCA, it works on sparse feature\n",
    "matrices.\n",
    "One issue with TSVD is that because of how it uses a random number generator,\n",
    "the signs of the output can flip between fittings. An easy workaround is to use\n",
    "fit only once per preprocessing pipeline, then use transform multiple times.\n",
    "As with linear discriminant analysis, we have to specify the number of features\n",
    "(components) we want outputted. This is done with the n_components\n",
    "parameter. A natural question is then: what is the optimum number of\n",
    "components? One strategy is to include n_components as a hyperparameter to\n",
    "optimize during model selection (i.e., choose the value for n_components that\n",
    "produces the best trained model). Alternatively, because TSVD provides us with\n",
    "the ratio of the original feature matrix’s variance explained by each component,\n",
    "we can select the number of components that explain a desired amount of variance (95% or 99% are common values). For example, in our solution the\n",
    "first three outputted components explain approximately 30% of the original\n",
    "data’s variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3003938539127293"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sum of first three components' explained variance ratios\n",
    "tsvd.explained_variance_ratio_[0:3].sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can automate the process by creating a function that runs TSVD with\n",
    "n_components set to one less than the number of original features and then\n",
    "calculate the number of components that explain a desired amount of the original\n",
    "data’s variance:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and run an TSVD with one less than number of features\n",
    "tsvd = TruncatedSVD(n_components=features_sparse.shape[1]-1)\n",
    "features_tsvd = tsvd.fit(features)\n",
    "# List of explained variances\n",
    "tsvd_var_ratios = tsvd.explained_variance_ratio_\n",
    "# Create a function\n",
    "def select_n_components(var_ratio, goal_var):\n",
    "# Set initial variance explained so far\n",
    "    total_variance = 0.0\n",
    "# Set initial number of features\n",
    "    n_components = 0\n",
    "# For the explained variance of each feature:\n",
    "    for explained_variance in var_ratio:\n",
    "# Add the explained variance to the total\n",
    "        total_variance += explained_variance\n",
    "# Add one to the number of components\n",
    "        n_components += 1\n",
    "# If we reach our goal level of explained variance\n",
    "        if total_variance >= goal_var:\n",
    "# End the loop\n",
    "            break\n",
    "# Return the number of components\n",
    "    return n_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_n_components(tsvd_var_ratios, 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b4f27d9b98637a93dfc92790c67a6714c8bfd98755bed637fb445c0198654de1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
