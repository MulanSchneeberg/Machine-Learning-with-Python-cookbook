{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have missing values in your data and want to fill in or predict their values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "import numpy as np\n",
    "from fancyimpute import KNN\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a simulated feature matrix\n",
    "features, _ = make_blobs(n_samples = 1000,\n",
    "n_features = 2,\n",
    "random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "standardized_features = scaler.fit_transform(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_value=standardized_features[0,0]\n",
    "standardized_features[0,0]=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Value: 0.8730186113995938\n",
      "Imputed Value: 1.0955332713113226\n"
     ]
    }
   ],
   "source": [
    "features_knn_imputed = KNN(k=5, verbose=0).fit_transform(standardized_features)\n",
    "print(\"True Value:\", true_value)\n",
    "print(\"Imputed Value:\", features_knn_imputed[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do this we treat the feature with\n",
    "missing values as a target vector and use the remaining subset of features to\n",
    "predict missing values. While we can use a wide range of machine learning\n",
    "algorithms to impute values, a popular choice is KNN. KNN is addressed in\n",
    "depth later in Chapter 14, but the short explanation is that the algorithm uses the\n",
    "k nearest observations (according to some distance metric) to predict the missing\n",
    "value. In our solution we predicted the missing value using the five closest\n",
    "observations\n",
    "The downside to KNN is that in order to know which observations are the\n",
    "closest to the missing value, it needs to calculate the distance between the\n",
    "missing value and every single observation. This is reasonable in smaller\n",
    "datasets, but quickly becomes problematic if a dataset has millions of\n",
    "observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use imputation, it is a good idea to create a binary feature indicating\n",
    "whether or not the observation contains an imputed value.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b4f27d9b98637a93dfc92790c67a6714c8bfd98755bed637fb445c0198654de1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
